{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "    print(f'Loading {file}')\n",
    "    loader = PyPDFLoader(file)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below text parses through extensions of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain_community.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain_community.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print('Document format not supported')\n",
    "        return None\n",
    "\n",
    "\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain_community.document_loaders import WikipediaLoader\n",
    "    print(f'Loading {query} from Wikipedia')\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embeddings_costs(texts):\n",
    "    import tiktoken\n",
    "    #enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "    #enc = tiktoken.encoding_for_model('text-embedding-3-large')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total tokens: {total_tokens}')\n",
    "    print(f'Total Embeddings cost in USD: {total_tokens / 1000 * 0.0004:.6f}')\n",
    "# print(embeddings_costs(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_of_fetch_embeddings(index_name):\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import PodSpec\n",
    "\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
    "    pc = pinecone.Pinecone()\n",
    "\n",
    "    if index_name in pc.list_indexes():\n",
    "        print(f'Index {index_name} already exists.  Loading embeddings...', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('OK')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddigns...', end='')\n",
    "\n",
    "        # create a new index\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            metric='cosine',\n",
    "            dimension=1536,\n",
    "            spec=PodSpec(\n",
    "                environment='gcp-starter'\n",
    "            )\n",
    "        )\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('OK')\n",
    "\n",
    "    return vector_store    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pineconde_index(index_name='all'):\n",
    "    import pinecone\n",
    "    import os\n",
    "    #pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))    \n",
    "    pc = pinecone.Pinecone()\n",
    "\n",
    "    if index_name == 'all':\n",
    "        indexes = pc.list_indexes().names()\n",
    "        for index in indexes:\n",
    "            print(f'Deleting all indexes...')\n",
    "            pc.delete_index(index)\n",
    "            print('OK')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name}...', end='')\n",
    "        pc.delete_index(index_name)\n",
    "        print('OK')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resources/files/us_constitution.pdf\n",
      "You have 41 pages in the document\n",
      "You have 1137 characters in page 20\n"
     ]
    }
   ],
   "source": [
    "data = load_document('resources/files/us_constitution.pdf')\n",
    "#print(data[1].page_content)\n",
    "#print(data[10].metadata)\n",
    "\n",
    "print(f'You have {len(data)} pages in the document')\n",
    "print(f'You have {len(data[20].page_content)} characters in page 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_document('resources/files/the_great_gatsby.docx')\n",
    "# print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_from_wikipedia('GPT-4')\n",
    "# data = load_from_wikipedia('GPT-4', lang='fr')  # French ouptput\n",
    "# print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 16711\n",
      "Total Embeddings cost in USD: 0.006684\n"
     ]
    }
   ],
   "source": [
    "print_embeddings_costs(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_pineconde_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddigns...OK\n"
     ]
    }
   ],
   "source": [
    "index_name = 'askadocument'\n",
    "vector_store = insert_of_fetch_embeddings(index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.invoke(q)\n",
    "    return answer\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history=[], k=3):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    result = crc.invoke({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the whole document about?', 'result': 'The excerpts provided are from the United States Constitution, which is the supreme law of the United States. It outlines the framework for the government, the rights of citizens, and the relationship between the federal government and the states. It establishes the three branches of government: the legislative branch, the executive branch, and the judicial branch, as well as their powers and responsibilities. The Constitution ensures the protection of individual liberties and sets the foundation for the United States government.'}\n"
     ]
    }
   ],
   "source": [
    "q = 'What is the whole document about?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit!\n",
      "Answer: {'query': 'what is first amendment of constitution?', 'result': 'The First Amendment of the Constitution of the United States ensures the protection of freedoms such as freedom of religion, freedom of speech, freedom of the press, and the right to peaceably assemble and petition the government.'}\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Answer: {'query': 'explain the concept of federalism as presented in US consitution?', 'result': 'Federalism, as presented in the US Constitution, is the principle of shared power between the national government and state governments. The US Constitution divides governmental authority between the federal government (national government) and state governments. Both levels of government have their own separate powers and responsibilities, and this division of power helps to prevent any one level of government from becoming too powerful. This is an important aspect of the US Constitution and helps maintain a balance of power within the US government system.'}\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Answer: {'query': 'describe bill of rights?', 'result': 'The Bill of Rights is a collective term for the first ten amendments to the United States Constitution. Its purpose is to protect individual liberties and limit the power of the government. The Bill of Rights includes rights such as freedom of speech, religion, and the right to bear arms.'}\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Quitting....\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "print('Write Quit or Exit to quit!')\n",
    "while True:\n",
    "    q = input(f'Ask Question #{1}: ')\n",
    "    i += 1\n",
    "    if q.lower() in ['quit', 'exit']:\n",
    "        print('Quitting....')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f'Answer: {answer}')\n",
    "    print(f'\\n {\"-\"*50} \\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes...\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "delete_pineconde_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChatGPT from Wikipedia\n",
      "Creating index chatgpt and embeddigns...OK\n"
     ]
    }
   ],
   "source": [
    "data = load_from_wikipedia('ChatGPT', 'ro')\n",
    "chunks = chunk_data(data)\n",
    "index_name = 'chatgpt'\n",
    "vector_store = insert_of_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Ce este ChatGPT?', 'result': 'ChatGPT este un membru al familiei de modele de limbaj generative pre-antrenate (GPT). A fost reglat fin peste o versiune îmbunătățită a GPT-3 a OpenAI cunoscută sub numele de „GPT-3.5”. Este utilizat pentru a genera texte pe baza input-ului furnizat de utilizatori și poate servi diverse scopuri, inclusiv educația.'}\n"
     ]
    }
   ],
   "source": [
    "q = \"Ce este ChatGPT?\"\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
